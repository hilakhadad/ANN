{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Assignment 3 - Part A - ANN"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "from sklearn.datasets import fetch_openml\n",
    "import ssl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "sys.path.insert(0, '..')"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## The dataset information"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70000, 784)\n",
      "(70000,)\n"
     ]
    }
   ],
   "source": [
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "X, y = fetch_openml('mnist_784', version=1, return_X_y=True)\n",
    "X = X.values\n",
    "y = y.astype(int).values\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Normalize to [-1, 1] range:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X = ((X / 255.) - .5) * 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Visualize the first digit of each class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 10 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(nrows=2, ncols=5, sharex=True, sharey=True)\n",
    "ax = ax.flatten()\n",
    "for i in range(10):\n",
    "    img = X[y == i][0].reshape(28, 28)\n",
    "    ax[i].imshow(img, cmap='Greys')\n",
    "\n",
    "ax[0].set_xticks([])\n",
    "ax[0].set_yticks([])\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Split into training, validation, and test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of X_test:(21000, 784)\n",
      "shape of y_test:(21000,)\n",
      "shape of X_train:(44000, 784)\n",
      "shape of y_train:(44000,)\n",
      "shape of X_valid:(5000, 784)\n",
      "shape of y_valid:(5000,)\n"
     ]
    }
   ],
   "source": [
    "X_temp, X_test, y_temp, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=123, stratify=y)\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X_temp, y_temp, test_size=5000, random_state=123, stratify=y_temp)\n",
    "\n",
    "print(f\"shape of X_test:{X_test.shape}\")\n",
    "print(f\"shape of y_test:{y_test.shape}\")\n",
    "print(f\"shape of X_train:{X_train.shape}\")\n",
    "print(f\"shape of y_train:{y_train.shape}\")\n",
    "print(f\"shape of X_valid:{X_valid.shape}\")\n",
    "print(f\"shape of y_valid:{y_valid.shape}\")\n",
    "\n",
    "# optional to free up some memory by deleting non-used arrays:\n",
    "del X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Original implementation of one layer perceptron"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "##########################\n",
    "### MODEL\n",
    "##########################\n",
    "\n",
    "def sigmoid(z):\n",
    "    return 1. / (1. + np.exp(-z))\n",
    "\n",
    "\n",
    "def int_to_onehot(y, num_labels):\n",
    "\n",
    "    ary = np.zeros((y.shape[0], num_labels))\n",
    "    for i, val in enumerate(y):\n",
    "        ary[i, val] = 1\n",
    "\n",
    "    return ary\n",
    "\n",
    "\n",
    "class NeuralNetMLP:\n",
    "\n",
    "    def __init__(self, num_features, num_hidden, num_classes, random_seed=123):\n",
    "        super().__init__()\n",
    "\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "        # hidden\n",
    "        rng = np.random.RandomState(random_seed)\n",
    "\n",
    "        self.weight_h = rng.normal(\n",
    "            loc=0.0, scale=0.1, size=(num_hidden, num_features))\n",
    "        self.bias_h = np.zeros(num_hidden)\n",
    "\n",
    "        # output\n",
    "        self.weight_out = rng.normal(\n",
    "            loc=0.0, scale=0.1, size=(num_classes, num_hidden))\n",
    "        self.bias_out = np.zeros(num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Hidden layer\n",
    "        # input dim: [n_examples, n_features] dot [n_hidden, n_features].T\n",
    "        # output dim: [n_examples, n_hidden]\n",
    "        z_h = np.dot(x, self.weight_h.T) + self.bias_h\n",
    "        a_h = sigmoid(z_h)\n",
    "\n",
    "        # Output layer\n",
    "        # input dim: [n_examples, n_hidden] dot [n_classes, n_hidden].T\n",
    "        # output dim: [n_examples, n_classes]\n",
    "        z_out = np.dot(a_h, self.weight_out.T) + self.bias_out\n",
    "        a_out = sigmoid(z_out)\n",
    "        return a_h, a_out\n",
    "\n",
    "    def backward(self, x, a_h, a_out, y):\n",
    "\n",
    "        #########################\n",
    "        ### Output layer weights\n",
    "        #########################\n",
    "\n",
    "        # onehot encoding\n",
    "        y_onehot = int_to_onehot(y, self.num_classes)\n",
    "\n",
    "        # Part 1: dLoss/dOutWeights\n",
    "        ## = dLoss/dOutAct * dOutAct/dOutNet * dOutNet/dOutWeight\n",
    "        ## where DeltaOut = dLoss/dOutAct * dOutAct/dOutNet\n",
    "        ## for convenient re-use\n",
    "\n",
    "        # input/output dim: [n_examples, n_classes]\n",
    "        d_loss__d_a_out = 2.*(a_out - y_onehot) / y.shape[0]\n",
    "\n",
    "        # input/output dim: [n_examples, n_classes]\n",
    "        d_a_out__d_z_out = a_out * (1. - a_out) # sigmoid derivative\n",
    "\n",
    "        # output dim: [n_examples, n_classes]\n",
    "        delta_out = d_loss__d_a_out * d_a_out__d_z_out # \"delta (rule) placeholder\"\n",
    "\n",
    "        # gradient for output weights\n",
    "\n",
    "        # [n_examples, n_hidden]\n",
    "        d_z_out__dw_out = a_h\n",
    "\n",
    "        # input dim: [n_classes, n_examples] dot [n_examples, n_hidden]\n",
    "        # output dim: [n_classes, n_hidden]\n",
    "        d_loss__dw_out = np.dot(delta_out.T, d_z_out__dw_out)\n",
    "        d_loss__db_out = np.sum(delta_out, axis=0)\n",
    "\n",
    "\n",
    "        #################################\n",
    "        # Part 2: dLoss/dHiddenWeights\n",
    "        ## = DeltaOut * dOutNet/dHiddenAct * dHiddenAct/dHiddenNet * dHiddenNet/dWeight\n",
    "\n",
    "        # [n_classes, n_hidden]\n",
    "        d_z_out__a_h = self.weight_out\n",
    "\n",
    "        # output dim: [n_examples, n_hidden]\n",
    "        d_loss__a_h = np.dot(delta_out, d_z_out__a_h)\n",
    "\n",
    "        # [n_examples, n_hidden]\n",
    "        d_a_h__d_z_h = a_h * (1. - a_h) # sigmoid derivative\n",
    "\n",
    "        # [n_examples, n_features]\n",
    "        d_z_h__d_w_h = x\n",
    "\n",
    "        # output dim: [n_hidden, n_features]\n",
    "        d_loss__d_w_h = np.dot((d_loss__a_h * d_a_h__d_z_h).T, d_z_h__d_w_h)\n",
    "        d_loss__d_b_h = np.sum((d_loss__a_h * d_a_h__d_z_h), axis=0)\n",
    "\n",
    "        return (d_loss__dw_out, d_loss__db_out,\n",
    "                d_loss__d_w_h, d_loss__d_b_h)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "one_layer_model = NeuralNetMLP(num_features=28*28,\n",
    "                     num_hidden=50,\n",
    "                     num_classes=10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "num_epochs = 50\n",
    "minibatch_size = 100\n",
    "\n",
    "def minibatch_generator(X, y, minibatch_size):\n",
    "    indices = np.arange(X.shape[0])\n",
    "    np.random.shuffle(indices)\n",
    "\n",
    "    for start_idx in range(0, indices.shape[0] - minibatch_size\n",
    "                           + 1, minibatch_size):\n",
    "        batch_idx = indices[start_idx:start_idx + minibatch_size]\n",
    "\n",
    "        yield X[batch_idx], y[batch_idx]\n",
    "\n",
    "\n",
    "# iterate over training epochs\n",
    "for i in range(num_epochs):\n",
    "\n",
    "    # iterate over minibatches\n",
    "    minibatch_gen = minibatch_generator(\n",
    "        X_train, y_train, minibatch_size)\n",
    "\n",
    "    for X_train_mini, y_train_mini in minibatch_gen:\n",
    "\n",
    "        break\n",
    "\n",
    "    break"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "def normi(arr):\n",
    "    return arr / arr.sum()\n",
    "\n",
    "def compute_measurements(nnet, X, y, num_labels=10, minibatch_size=100):\n",
    "    mse, correct_pred, num_examples = 0., 0, 0\n",
    "    minibatch_gen = minibatch_generator(X, y, minibatch_size)\n",
    "\n",
    "    y_true = np.array([])\n",
    "    y_score = np.empty((1, 10))\n",
    "    for i, (features, targets) in enumerate(minibatch_gen):\n",
    "        _, probas = nnet.forward(features)\n",
    "        predicted_labels = np.argmax(probas, axis=1)\n",
    "        y_true = np.concatenate((y_true, targets))\n",
    "        probas_norm = np.apply_along_axis(normi, 1, probas)\n",
    "        y_score = np.concatenate((y_score, probas_norm))\n",
    "\n",
    "        onehot_targets = int_to_onehot(targets, num_labels=num_labels)\n",
    "        loss = np.mean((onehot_targets - probas)**2)\n",
    "        correct_pred += (predicted_labels == targets).sum()\n",
    "\n",
    "        num_examples += targets.shape[0]\n",
    "        mse += loss\n",
    "\n",
    "    y_score = y_score[1:]\n",
    "\n",
    "    macro_auc = roc_auc_score(y_true, y_score, multi_class='ovr')\n",
    "    mse = mse/i\n",
    "    acc = correct_pred/num_examples\n",
    "\n",
    "    return mse, acc, macro_auc"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial valid MSE in one layer model: 0.3\n",
      "Initial valid accuracy in one layer model: 9.2%\n"
     ]
    }
   ],
   "source": [
    "mse, acc, _ = compute_measurements(one_layer_model, X_valid, y_valid)\n",
    "print(f'Initial valid MSE in one layer model: {mse:.1f}')\n",
    "print(f'Initial valid accuracy in one layer model: {acc*100:.1f}%')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "def train(model, X_train, y_train, X_valid, y_valid, num_epochs,\n",
    "          learning_rate=0.1):\n",
    "\n",
    "    epoch_loss = []\n",
    "    epoch_train_acc = []\n",
    "    epoch_valid_acc = []\n",
    "\n",
    "    for e in range(num_epochs):\n",
    "\n",
    "        # iterate over minibatches\n",
    "        minibatch_gen = minibatch_generator(\n",
    "            X_train, y_train, minibatch_size)\n",
    "\n",
    "        for X_train_mini, y_train_mini in minibatch_gen:\n",
    "\n",
    "            #### Compute outputs ####\n",
    "            a_h, a_out = model.forward(X_train_mini)\n",
    "\n",
    "            #### Compute gradients ####\n",
    "            d_loss__d_w_out, d_loss__d_b_out, d_loss__d_w_h, d_loss__d_b_h = \\\n",
    "                model.backward(X_train_mini, a_h, a_out, y_train_mini)\n",
    "\n",
    "            #### Update weights ####\n",
    "            model.weight_h -= learning_rate * d_loss__d_w_h\n",
    "            model.bias_h -= learning_rate * d_loss__d_b_h\n",
    "            model.weight_out -= learning_rate * d_loss__d_w_out\n",
    "            model.bias_out -= learning_rate * d_loss__d_b_out\n",
    "\n",
    "        #### Epoch Logging ####\n",
    "        train_mse, train_acc, _ = compute_measurements(model, X_train, y_train)\n",
    "        valid_mse, valid_acc, _ = compute_measurements(model, X_valid, y_valid)\n",
    "        train_acc, valid_acc = train_acc*100, valid_acc*100\n",
    "        epoch_train_acc.append(train_acc)\n",
    "        epoch_valid_acc.append(valid_acc)\n",
    "        epoch_loss.append(train_mse)\n",
    "        print(f'Epoch: {e+1:03d}/{num_epochs:03d} '\n",
    "              f'| Train MSE: {train_mse:.2f} '\n",
    "              f'| Train Acc: {train_acc:.2f}% '\n",
    "              f'| Valid Acc: {valid_acc:.2f}%')\n",
    "\n",
    "    return epoch_loss, epoch_train_acc, epoch_valid_acc"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001/050 | Train MSE: 0.06 | Train Acc: 72.79% | Valid Acc: 72.92%\n",
      "Epoch: 002/050 | Train MSE: 0.04 | Train Acc: 83.11% | Valid Acc: 82.48%\n",
      "Epoch: 003/050 | Train MSE: 0.03 | Train Acc: 86.96% | Valid Acc: 86.20%\n",
      "Epoch: 004/050 | Train MSE: 0.02 | Train Acc: 88.48% | Valid Acc: 88.10%\n",
      "Epoch: 005/050 | Train MSE: 0.02 | Train Acc: 89.45% | Valid Acc: 89.10%\n",
      "Epoch: 006/050 | Train MSE: 0.02 | Train Acc: 90.06% | Valid Acc: 89.64%\n",
      "Epoch: 007/050 | Train MSE: 0.02 | Train Acc: 90.53% | Valid Acc: 90.34%\n",
      "Epoch: 008/050 | Train MSE: 0.02 | Train Acc: 90.84% | Valid Acc: 90.66%\n",
      "Epoch: 009/050 | Train MSE: 0.02 | Train Acc: 91.33% | Valid Acc: 90.98%\n",
      "Epoch: 010/050 | Train MSE: 0.02 | Train Acc: 91.46% | Valid Acc: 91.24%\n",
      "Epoch: 011/050 | Train MSE: 0.01 | Train Acc: 91.67% | Valid Acc: 91.16%\n",
      "Epoch: 012/050 | Train MSE: 0.01 | Train Acc: 91.88% | Valid Acc: 91.48%\n",
      "Epoch: 013/050 | Train MSE: 0.01 | Train Acc: 92.23% | Valid Acc: 91.66%\n",
      "Epoch: 014/050 | Train MSE: 0.01 | Train Acc: 92.31% | Valid Acc: 91.94%\n",
      "Epoch: 015/050 | Train MSE: 0.01 | Train Acc: 92.50% | Valid Acc: 91.98%\n",
      "Epoch: 016/050 | Train MSE: 0.01 | Train Acc: 92.70% | Valid Acc: 92.22%\n",
      "Epoch: 017/050 | Train MSE: 0.01 | Train Acc: 92.87% | Valid Acc: 92.48%\n",
      "Epoch: 018/050 | Train MSE: 0.01 | Train Acc: 92.99% | Valid Acc: 92.54%\n",
      "Epoch: 019/050 | Train MSE: 0.01 | Train Acc: 93.07% | Valid Acc: 92.54%\n",
      "Epoch: 020/050 | Train MSE: 0.01 | Train Acc: 93.18% | Valid Acc: 92.56%\n",
      "Epoch: 021/050 | Train MSE: 0.01 | Train Acc: 93.27% | Valid Acc: 92.76%\n",
      "Epoch: 022/050 | Train MSE: 0.01 | Train Acc: 93.44% | Valid Acc: 92.88%\n",
      "Epoch: 023/050 | Train MSE: 0.01 | Train Acc: 93.51% | Valid Acc: 92.92%\n",
      "Epoch: 024/050 | Train MSE: 0.01 | Train Acc: 93.62% | Valid Acc: 93.06%\n",
      "Epoch: 025/050 | Train MSE: 0.01 | Train Acc: 93.71% | Valid Acc: 93.12%\n",
      "Epoch: 026/050 | Train MSE: 0.01 | Train Acc: 93.77% | Valid Acc: 93.24%\n",
      "Epoch: 027/050 | Train MSE: 0.01 | Train Acc: 93.90% | Valid Acc: 93.20%\n",
      "Epoch: 028/050 | Train MSE: 0.01 | Train Acc: 94.01% | Valid Acc: 93.26%\n",
      "Epoch: 029/050 | Train MSE: 0.01 | Train Acc: 94.03% | Valid Acc: 93.48%\n",
      "Epoch: 030/050 | Train MSE: 0.01 | Train Acc: 94.09% | Valid Acc: 93.26%\n",
      "Epoch: 031/050 | Train MSE: 0.01 | Train Acc: 94.14% | Valid Acc: 93.56%\n",
      "Epoch: 032/050 | Train MSE: 0.01 | Train Acc: 94.26% | Valid Acc: 93.52%\n",
      "Epoch: 033/050 | Train MSE: 0.01 | Train Acc: 94.31% | Valid Acc: 93.48%\n",
      "Epoch: 034/050 | Train MSE: 0.01 | Train Acc: 94.41% | Valid Acc: 93.70%\n",
      "Epoch: 035/050 | Train MSE: 0.01 | Train Acc: 94.49% | Valid Acc: 93.78%\n",
      "Epoch: 036/050 | Train MSE: 0.01 | Train Acc: 94.53% | Valid Acc: 93.74%\n",
      "Epoch: 037/050 | Train MSE: 0.01 | Train Acc: 94.53% | Valid Acc: 93.78%\n",
      "Epoch: 038/050 | Train MSE: 0.01 | Train Acc: 94.67% | Valid Acc: 93.86%\n",
      "Epoch: 039/050 | Train MSE: 0.01 | Train Acc: 94.76% | Valid Acc: 93.72%\n",
      "Epoch: 040/050 | Train MSE: 0.01 | Train Acc: 94.73% | Valid Acc: 93.90%\n",
      "Epoch: 041/050 | Train MSE: 0.01 | Train Acc: 94.80% | Valid Acc: 93.96%\n",
      "Epoch: 042/050 | Train MSE: 0.01 | Train Acc: 94.83% | Valid Acc: 93.86%\n",
      "Epoch: 043/050 | Train MSE: 0.01 | Train Acc: 94.92% | Valid Acc: 94.12%\n",
      "Epoch: 044/050 | Train MSE: 0.01 | Train Acc: 94.96% | Valid Acc: 94.12%\n",
      "Epoch: 045/050 | Train MSE: 0.01 | Train Acc: 95.00% | Valid Acc: 94.14%\n",
      "Epoch: 046/050 | Train MSE: 0.01 | Train Acc: 95.06% | Valid Acc: 94.14%\n",
      "Epoch: 047/050 | Train MSE: 0.01 | Train Acc: 95.11% | Valid Acc: 94.14%\n",
      "Epoch: 048/050 | Train MSE: 0.01 | Train Acc: 95.18% | Valid Acc: 94.32%\n",
      "Epoch: 049/050 | Train MSE: 0.01 | Train Acc: 95.19% | Valid Acc: 94.40%\n",
      "Epoch: 050/050 | Train MSE: 0.01 | Train Acc: 95.26% | Valid Acc: 94.32%\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(123) # for the training set shuffling\n",
    "\n",
    "one_layer_model_epoch_loss, one_layer_model_epoch_train_acc, one_layer_model_epoch_valid_acc = \\\n",
    "    train(one_layer_model, X_train, y_train, X_valid, y_valid, num_epochs=50, learning_rate=0.1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One layer test accuracy: 94.28%\n"
     ]
    }
   ],
   "source": [
    "one_layer_model_test_mse, one_layer_model_test_acc, one_layer_model_test_macro_auc = compute_measurements(one_layer_model, X_test, y_test)\n",
    "print(f'One layer test accuracy: {one_layer_model_test_acc*100:.2f}%')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Implementing of a two layers perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "##########################\n",
    "### MODEL\n",
    "##########################\n",
    "\n",
    "def sigmoid(z):                                        \n",
    "    return 1. / (1. + np.exp(-z))\n",
    "\n",
    "\n",
    "def int_to_onehot(y, num_labels):\n",
    "\n",
    "    ary = np.zeros((y.shape[0], num_labels))\n",
    "    for i, val in enumerate(y):\n",
    "        ary[i, val] = 1\n",
    "\n",
    "    return ary\n",
    "\n",
    "\n",
    "class NeuralNetMLP:\n",
    "\n",
    "    def __init__(self, num_features, num_hidden, num_hidden2, num_classes, random_seed=123):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.num_classes = num_classes\n",
    "        \n",
    "        # hidden\n",
    "        rng = np.random.RandomState(random_seed)\n",
    "        \n",
    "        self.weight_h = rng.normal(\n",
    "            loc=0.0, scale=0.1, size=(num_hidden, num_features))\n",
    "        self.bias_h = np.zeros(num_hidden)\n",
    "\n",
    "        self.weight_h2 = rng.normal(\n",
    "            loc=0.0, scale=0.1, size=(num_hidden2, num_hidden))\n",
    "        self.bias_h2 = np.zeros(num_hidden2)\n",
    "        \n",
    "        # output\n",
    "        self.weight_out = rng.normal(\n",
    "            loc=0.0, scale=0.1, size=(num_classes, num_hidden2))\n",
    "        self.bias_out = np.zeros(num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Hidden layer\n",
    "        # input dim: [n_examples, n_features] dot [n_hidden, n_features].T\n",
    "        # output dim: [n_examples, n_hidden]\n",
    "        z_h = np.dot(x, self.weight_h.T) + self.bias_h\n",
    "        a_h = sigmoid(z_h)\n",
    "\n",
    "        # Hidden layer2\n",
    "        # input dim: [n_examples, n_hidden] dot [n_hidden2, n_hidden].T\n",
    "        # output dim: [n_examples, n_hidden2]\n",
    "        z_h2 = np.dot(a_h, self.weight_h2.T) + self.bias_h2\n",
    "        a_h2 = sigmoid(z_h2)\n",
    "\n",
    "        # Output layer\n",
    "        # input dim: [n_examples, n_hidden2] dot [n_classes, n_hidden2].T\n",
    "        # output dim: [n_examples, n_classes]\n",
    "        z_out = np.dot(a_h2, self.weight_out.T) + self.bias_out\n",
    "        a_out = sigmoid(z_out)\n",
    "        return a_h, a_h2, a_out\n",
    "\n",
    "    def backward(self, x, a_h, a_h2, a_out, y):\n",
    "    \n",
    "        #########################\n",
    "        ### Output layer weights\n",
    "        #########################\n",
    "        \n",
    "        # onehot encoding\n",
    "        y_onehot = int_to_onehot(y, self.num_classes)\n",
    "\n",
    "        # Part 1: dLoss/dOutWeights\n",
    "        ## = dLoss/dOutAct * dOutAct/dOutNet * dOutNet/dOutWeight\n",
    "        ## where DeltaOut = dLoss/dOutAct * dOutAct/dOutNet\n",
    "        ## for convenient re-use\n",
    "        \n",
    "        # input/output dim: [n_examples, n_classes]\n",
    "        d_loss__d_a_out = 2.*(a_out - y_onehot) / y.shape[0]\n",
    "\n",
    "        # input/output dim: [n_examples, n_classes]\n",
    "        d_a_out__d_z_out = a_out * (1. - a_out) # sigmoid derivative\n",
    "\n",
    "        # output dim: [n_examples, n_classes]\n",
    "        delta_out = d_loss__d_a_out * d_a_out__d_z_out # \"delta (rule) placeholder\"\n",
    "\n",
    "        # gradient for output weights\n",
    "        \n",
    "        # [n_examples, n_hidden2]\n",
    "        d_z_out__dw_out = a_h2\n",
    "\n",
    "        # input dim: [n_classes, n_examples] dot [n_examples, n_hidden2]\n",
    "        # output dim: [n_classes, n_hidden2]\n",
    "        d_loss__dw_out = np.dot(delta_out.T, d_z_out__dw_out)\n",
    "        d_loss__db_out = np.sum(delta_out, axis=0)\n",
    "\n",
    "\n",
    "        #################################\n",
    "        # Part 2: dLoss/dHiddenWeights2\n",
    "        ## = DeltaOut * dOutNet/dHiddenAct2 * dHiddenAct2/dHiddenNet2 * dHiddenNet2/dWeight2\n",
    "\n",
    "        # [n_classes, n_hidden2]\n",
    "        d_z_out__a_h2 = self.weight_out\n",
    "\n",
    "        # output dim: [n_examples, n_hidden2]\n",
    "        d_loss__a_h2 = np.dot(delta_out, d_z_out__a_h2)\n",
    "\n",
    "        # [n_examples, n_hidden2]\n",
    "        d_a_h__d_z_h2 = a_h2 * (1. - a_h2) # sigmoid derivative\n",
    "\n",
    "        delta_h2 = d_loss__a_h2 * d_a_h__d_z_h2\n",
    "\n",
    "        # [n_examples, n_hidden]\n",
    "        d_z_h__d_w_h2 = a_h\n",
    "\n",
    "        # output dim: [n_hidden2, n_hidden]\n",
    "        d_loss__d_w_h2 = np.dot((d_loss__a_h2 * d_a_h__d_z_h2).T, d_z_h__d_w_h2)\n",
    "        d_loss__d_b_h2 = np.sum((d_loss__a_h2 * d_a_h__d_z_h2), axis=0)\n",
    "\n",
    "        #################################        \n",
    "        # Part 3: dLoss/dHiddenWeights\n",
    "        ## = DeltaOut * dOutNet/dHiddenAct * dHiddenAct/dHiddenNet * dHiddenNet/dWeight\n",
    "        \n",
    "        # [n_hidden2, n_hidden]\n",
    "        d_z_out__a_h = self.weight_h2\n",
    "        \n",
    "        # output dim: [n_examples, n_hidden]\n",
    "        d_loss__a_h = np.dot(delta_h2, d_z_out__a_h)\n",
    "        \n",
    "        # [n_examples, n_hidden]\n",
    "        d_a_h__d_z_h = a_h * (1. - a_h) # sigmoid derivative\n",
    "        \n",
    "        # [n_examples, n_features]\n",
    "        d_z_h__d_w_h = x\n",
    "        \n",
    "        # output dim: [n_hidden, n_features]\n",
    "        d_loss__d_w_h = np.dot((d_loss__a_h * d_a_h__d_z_h).T, d_z_h__d_w_h)\n",
    "        d_loss__d_b_h = np.sum((d_loss__a_h * d_a_h__d_z_h), axis=0)\n",
    "\n",
    "        return (d_loss__dw_out, d_loss__db_out,\n",
    "                d_loss__d_w_h2, d_loss__d_b_h2,\n",
    "                d_loss__d_w_h, d_loss__d_b_h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "two_layers_model = NeuralNetMLP(num_features=28*28,\n",
    "                     num_hidden=50,\n",
    "                     num_hidden2=50,\n",
    "                     num_classes=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Coding the neural network training loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Defining data loaders:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "num_epochs = 50\n",
    "minibatch_size = 100\n",
    "\n",
    "def minibatch_generator(X, y, minibatch_size):\n",
    "    indices = np.arange(X.shape[0])\n",
    "    np.random.shuffle(indices)\n",
    "\n",
    "    for start_idx in range(0, indices.shape[0] - minibatch_size \n",
    "                           + 1, minibatch_size):\n",
    "        batch_idx = indices[start_idx:start_idx + minibatch_size]\n",
    "        \n",
    "        yield X[batch_idx], y[batch_idx]\n",
    "\n",
    "        \n",
    "# iterate over training epochs\n",
    "for i in range(num_epochs):\n",
    "\n",
    "    # iterate over minibatches\n",
    "    minibatch_gen = minibatch_generator(\n",
    "        X_train, y_train, minibatch_size)\n",
    "    \n",
    "    for X_train_mini, y_train_mini in minibatch_gen:\n",
    "\n",
    "        break\n",
    "        \n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Defining a function to compute the loss and accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def compute_measurements(nnet, X, y, num_labels=10, minibatch_size=100):\n",
    "    mse, correct_pred, num_examples = 0., 0, 0\n",
    "    minibatch_gen = minibatch_generator(X, y, minibatch_size)\n",
    "\n",
    "    y_true = np.array([])\n",
    "    y_score = np.empty((1, 10))\n",
    "    for i, (features, targets) in enumerate(minibatch_gen):\n",
    "        _,_, probas = nnet.forward(features)\n",
    "        predicted_labels = np.argmax(probas, axis=1)\n",
    "        y_true = np.concatenate((y_true, targets))\n",
    "        probas_norm = np.apply_along_axis(normi, 1, probas)\n",
    "        y_score = np.concatenate((y_score, probas_norm))\n",
    "\n",
    "        onehot_targets = int_to_onehot(targets, num_labels=num_labels)\n",
    "        loss = np.mean((onehot_targets - probas)**2)\n",
    "        correct_pred += (predicted_labels == targets).sum()\n",
    "\n",
    "        num_examples += targets.shape[0]\n",
    "        mse += loss\n",
    "\n",
    "    y_score = y_score[1:]\n",
    "    macro_auc = roc_auc_score(y_true, y_score, multi_class='ovr')\n",
    "\n",
    "    mse = mse/i\n",
    "    acc = correct_pred/num_examples\n",
    "    return mse, acc, macro_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial valid MSE in two layers model: 0.3\n",
      "Initial valid accuracy in two layers model: 9.0%\n"
     ]
    }
   ],
   "source": [
    "mse, acc, _ = compute_measurements(two_layers_model, X_valid, y_valid)\n",
    "print(f'Initial valid MSE in two layers model: {mse:.1f}')\n",
    "print(f'Initial valid accuracy in two layers model: {acc*100:.1f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def train(model, X_train, y_train, X_valid, y_valid, num_epochs,\n",
    "          learning_rate=0.1):\n",
    "    \n",
    "    epoch_loss = []\n",
    "    epoch_train_acc = []\n",
    "    epoch_valid_acc = []\n",
    "    \n",
    "    for e in range(num_epochs):\n",
    "\n",
    "        # iterate over minibatches\n",
    "        minibatch_gen = minibatch_generator(\n",
    "            X_train, y_train, minibatch_size)\n",
    "\n",
    "        for X_train_mini, y_train_mini in minibatch_gen:\n",
    "            \n",
    "            #### Compute outputs ####\n",
    "            a_h, a_h2, a_out = model.forward(X_train_mini)\n",
    "\n",
    "            #### Compute gradients ####\n",
    "            d_loss__d_w_out, d_loss__d_b_out, d_loss__d_w_h2, d_loss__d_b_h2, d_loss__d_w_h, d_loss__d_b_h = \\\n",
    "                model.backward(X_train_mini, a_h, a_h2, a_out, y_train_mini)\n",
    "\n",
    "            #### Update weights ####\n",
    "            model.weight_h -= learning_rate * d_loss__d_w_h\n",
    "            model.bias_h -= learning_rate * d_loss__d_b_h\n",
    "            model.weight_h2 -= learning_rate * d_loss__d_w_h2\n",
    "            model.bias_h2 -= learning_rate * d_loss__d_b_h2\n",
    "            model.weight_out -= learning_rate * d_loss__d_w_out\n",
    "            model.bias_out -= learning_rate * d_loss__d_b_out\n",
    "        \n",
    "        #### Epoch Logging ####        \n",
    "        train_mse, train_acc, _ = compute_measurements(model, X_train, y_train)\n",
    "        valid_mse, valid_acc, _ = compute_measurements(model, X_valid, y_valid)\n",
    "        train_acc, valid_acc = train_acc*100, valid_acc*100\n",
    "        epoch_train_acc.append(train_acc)\n",
    "        epoch_valid_acc.append(valid_acc)\n",
    "        epoch_loss.append(train_mse)\n",
    "        print(f'Epoch: {e+1:03d}/{num_epochs:03d} '\n",
    "              f'| Train MSE: {train_mse:.2f} '\n",
    "              f'| Train Acc: {train_acc:.2f}% '\n",
    "              f'| Valid Acc: {valid_acc:.2f}%')\n",
    "\n",
    "    return epoch_loss, epoch_train_acc, epoch_valid_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001/050 | Train MSE: 0.09 | Train Acc: 20.81% | Valid Acc: 20.74%\n",
      "Epoch: 002/050 | Train MSE: 0.09 | Train Acc: 26.82% | Valid Acc: 26.68%\n",
      "Epoch: 003/050 | Train MSE: 0.08 | Train Acc: 31.01% | Valid Acc: 30.58%\n",
      "Epoch: 004/050 | Train MSE: 0.07 | Train Acc: 50.75% | Valid Acc: 50.86%\n",
      "Epoch: 005/050 | Train MSE: 0.06 | Train Acc: 62.88% | Valid Acc: 63.08%\n",
      "Epoch: 006/050 | Train MSE: 0.05 | Train Acc: 70.61% | Valid Acc: 70.60%\n",
      "Epoch: 007/050 | Train MSE: 0.04 | Train Acc: 79.21% | Valid Acc: 79.32%\n",
      "Epoch: 008/050 | Train MSE: 0.03 | Train Acc: 84.49% | Valid Acc: 84.82%\n",
      "Epoch: 009/050 | Train MSE: 0.03 | Train Acc: 86.76% | Valid Acc: 87.00%\n",
      "Epoch: 010/050 | Train MSE: 0.02 | Train Acc: 87.76% | Valid Acc: 87.92%\n",
      "Epoch: 011/050 | Train MSE: 0.02 | Train Acc: 88.45% | Valid Acc: 88.42%\n",
      "Epoch: 012/050 | Train MSE: 0.02 | Train Acc: 89.08% | Valid Acc: 88.86%\n",
      "Epoch: 013/050 | Train MSE: 0.02 | Train Acc: 89.69% | Valid Acc: 89.58%\n",
      "Epoch: 014/050 | Train MSE: 0.02 | Train Acc: 90.04% | Valid Acc: 89.88%\n",
      "Epoch: 015/050 | Train MSE: 0.02 | Train Acc: 90.39% | Valid Acc: 89.84%\n",
      "Epoch: 016/050 | Train MSE: 0.02 | Train Acc: 90.70% | Valid Acc: 90.34%\n",
      "Epoch: 017/050 | Train MSE: 0.02 | Train Acc: 91.10% | Valid Acc: 90.58%\n",
      "Epoch: 018/050 | Train MSE: 0.02 | Train Acc: 91.34% | Valid Acc: 90.72%\n",
      "Epoch: 019/050 | Train MSE: 0.01 | Train Acc: 91.50% | Valid Acc: 90.98%\n",
      "Epoch: 020/050 | Train MSE: 0.01 | Train Acc: 91.77% | Valid Acc: 91.18%\n",
      "Epoch: 021/050 | Train MSE: 0.01 | Train Acc: 92.00% | Valid Acc: 91.38%\n",
      "Epoch: 022/050 | Train MSE: 0.01 | Train Acc: 92.15% | Valid Acc: 91.36%\n",
      "Epoch: 023/050 | Train MSE: 0.01 | Train Acc: 92.31% | Valid Acc: 91.86%\n",
      "Epoch: 024/050 | Train MSE: 0.01 | Train Acc: 92.59% | Valid Acc: 92.20%\n",
      "Epoch: 025/050 | Train MSE: 0.01 | Train Acc: 92.74% | Valid Acc: 92.14%\n",
      "Epoch: 026/050 | Train MSE: 0.01 | Train Acc: 92.89% | Valid Acc: 92.40%\n",
      "Epoch: 027/050 | Train MSE: 0.01 | Train Acc: 93.05% | Valid Acc: 92.62%\n",
      "Epoch: 028/050 | Train MSE: 0.01 | Train Acc: 93.26% | Valid Acc: 92.64%\n",
      "Epoch: 029/050 | Train MSE: 0.01 | Train Acc: 93.42% | Valid Acc: 92.84%\n",
      "Epoch: 030/050 | Train MSE: 0.01 | Train Acc: 93.56% | Valid Acc: 93.02%\n",
      "Epoch: 031/050 | Train MSE: 0.01 | Train Acc: 93.62% | Valid Acc: 93.26%\n",
      "Epoch: 032/050 | Train MSE: 0.01 | Train Acc: 93.76% | Valid Acc: 93.22%\n",
      "Epoch: 033/050 | Train MSE: 0.01 | Train Acc: 93.85% | Valid Acc: 93.16%\n",
      "Epoch: 034/050 | Train MSE: 0.01 | Train Acc: 93.97% | Valid Acc: 93.42%\n",
      "Epoch: 035/050 | Train MSE: 0.01 | Train Acc: 94.08% | Valid Acc: 93.56%\n",
      "Epoch: 036/050 | Train MSE: 0.01 | Train Acc: 94.19% | Valid Acc: 93.58%\n",
      "Epoch: 037/050 | Train MSE: 0.01 | Train Acc: 94.19% | Valid Acc: 93.48%\n",
      "Epoch: 038/050 | Train MSE: 0.01 | Train Acc: 94.46% | Valid Acc: 93.76%\n",
      "Epoch: 039/050 | Train MSE: 0.01 | Train Acc: 94.51% | Valid Acc: 93.78%\n",
      "Epoch: 040/050 | Train MSE: 0.01 | Train Acc: 94.67% | Valid Acc: 93.80%\n",
      "Epoch: 041/050 | Train MSE: 0.01 | Train Acc: 94.71% | Valid Acc: 93.96%\n",
      "Epoch: 042/050 | Train MSE: 0.01 | Train Acc: 94.83% | Valid Acc: 93.90%\n",
      "Epoch: 043/050 | Train MSE: 0.01 | Train Acc: 94.89% | Valid Acc: 94.10%\n",
      "Epoch: 044/050 | Train MSE: 0.01 | Train Acc: 94.93% | Valid Acc: 94.14%\n",
      "Epoch: 045/050 | Train MSE: 0.01 | Train Acc: 95.09% | Valid Acc: 94.22%\n",
      "Epoch: 046/050 | Train MSE: 0.01 | Train Acc: 95.16% | Valid Acc: 94.18%\n",
      "Epoch: 047/050 | Train MSE: 0.01 | Train Acc: 95.25% | Valid Acc: 94.30%\n",
      "Epoch: 048/050 | Train MSE: 0.01 | Train Acc: 95.32% | Valid Acc: 94.40%\n",
      "Epoch: 049/050 | Train MSE: 0.01 | Train Acc: 95.35% | Valid Acc: 94.58%\n",
      "Epoch: 050/050 | Train MSE: 0.01 | Train Acc: 95.43% | Valid Acc: 94.66%\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(123) # for the training set shuffling\n",
    "\n",
    "two_layers_model_epoch_loss, two_layers_model_epoch_train_acc, two_layers_model_epoch_valid_acc = train(\n",
    "    two_layers_model, X_train, y_train, X_valid, y_valid,\n",
    "    num_epochs=50, learning_rate=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Two layers model test accuracy: 94.42%\n"
     ]
    }
   ],
   "source": [
    "two_layers_model_test_mse, two_layers_model_test_acc, two_layers_model_test_macro_auc = compute_measurements(two_layers_model, X_test, y_test)\n",
    "print(f'Two layers model test accuracy: {two_layers_model_test_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Pytorch Full ANN"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, photos, labels, transform=None, target_transform=None):\n",
    "        self.img_labels = labels\n",
    "        self.img_dir = photos\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.img_dir[idx]\n",
    "        label = self.img_labels[idx]\n",
    "        image = torch.from_numpy(image).float()\n",
    "        label = torch.tensor(label, dtype=torch.long)\n",
    "        return image, label"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "n_epochs = 50\n",
    "batch_size_train = 100\n",
    "batch_size_test = 100\n",
    "learning_rate = 0.1\n",
    "log_interval = 10\n",
    "\n",
    "random_seed = 1\n",
    "torch.backends.cudnn.enabled = False\n",
    "torch.manual_seed(random_seed)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "  CustomImageDataset(X_temp, y_temp),\n",
    "  batch_size=batch_size_train, shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "  CustomImageDataset(X_test, y_test),\n",
    "  batch_size=batch_size_train, shuffle=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "examples = enumerate(test_loader)\n",
    "batch_idx, (example_data, example_targets) = next(examples)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(28*28, 50)\n",
    "        self.final = nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28*28)\n",
    "        x = self.fc1(x)\n",
    "        x = torch.sigmoid(self.final(x))\n",
    "        return F.log_softmax(x, dim = 1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "network = Net()\n",
    "optimizer = optim.SGD(network.parameters(), lr=learning_rate)\n",
    "test_losses = []\n",
    "test_counter = [i*len(train_loader.dataset) for i in range(n_epochs + 1)]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "  network.train()\n",
    "  for batch_idx, (data, target) in enumerate(train_loader):\n",
    "    optimizer.zero_grad()\n",
    "    output = network(data)\n",
    "    loss = F.nll_loss(output, target)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "  print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "        epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "        100. * batch_idx / len(train_loader), loss.item()))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "def test():\n",
    "  network.eval()\n",
    "  test_loss = 0\n",
    "  correct = 0\n",
    "\n",
    "  y_true = np.array([])\n",
    "  y_score = np.empty((1, 10))\n",
    "  with torch.no_grad():\n",
    "    for data, target in test_loader:\n",
    "      y_true = np.concatenate((y_true, target.numpy()))\n",
    "      output = network(data)\n",
    "      y_score = np.concatenate((y_score, F.softmax(output).numpy()))\n",
    "      test_loss += F.nll_loss(output, target, size_average=False).item()\n",
    "      pred = output.data.max(1, keepdim=True)[1]\n",
    "      correct += pred.eq(target.data.view_as(pred)).sum()\n",
    "  test_loss /= len(test_loader.dataset)\n",
    "  test_losses.append(test_loss)\n",
    "  test_acc_torch = 100. * correct / len(test_loader.dataset)\n",
    "  print('\\nTest set: Avg. loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n",
    "    test_loss, correct, len(test_loader.dataset),\n",
    "    test_acc_torch))\n",
    "  y_score = y_score[1:]\n",
    "  macro_auc = roc_auc_score(y_true, y_score, multi_class='ovr')\n",
    "  return test_acc_torch, macro_auc"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "def test():\n",
    "  network.eval()\n",
    "  test_loss = 0\n",
    "  correct = 0\n",
    "\n",
    "  y_true = np.array([])\n",
    "  y_score = np.empty((1, 10))\n",
    "  with torch.no_grad():\n",
    "    for data, target in test_loader:\n",
    "      y_true = np.concatenate((y_true, target.numpy()))\n",
    "      output = network(data)\n",
    "      y_score = np.concatenate((y_score, F.softmax(output, dim = 1).numpy()))\n",
    "      test_loss += F.nll_loss(output, target, size_average=False).item()\n",
    "      pred = output.data.max(1, keepdim=True)[1]\n",
    "      correct += pred.eq(target.data.view_as(pred)).sum()\n",
    "  test_loss /= len(test_loader.dataset)\n",
    "  test_losses.append(test_loss)\n",
    "  test_acc_torch = 100. * correct / len(test_loader.dataset)\n",
    "  print('\\nTest set: Avg. loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n",
    "    test_loss, correct, len(test_loader.dataset),\n",
    "    test_acc_torch))\n",
    "  y_score = y_score[1:]\n",
    "  macro_auc = roc_auc_score(y_true, y_score, multi_class='ovr')\n",
    "  return test_acc_torch, macro_auc"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hilak\\anaconda3\\envs\\ANN\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 2.3044, Accuracy: 2682/21000 (12.77%)\n",
      "\n",
      "Initial test accuracy in torch model:12.8%\n",
      "Train Epoch: 1 [48900/49000 (100%)]\tLoss: 1.617339\n",
      "Train Epoch: 2 [48900/49000 (100%)]\tLoss: 1.609707\n",
      "Train Epoch: 3 [48900/49000 (100%)]\tLoss: 1.608815\n",
      "Train Epoch: 4 [48900/49000 (100%)]\tLoss: 1.596146\n",
      "Train Epoch: 5 [48900/49000 (100%)]\tLoss: 1.581653\n",
      "Train Epoch: 6 [48900/49000 (100%)]\tLoss: 1.586847\n",
      "Train Epoch: 7 [48900/49000 (100%)]\tLoss: 1.554318\n",
      "Train Epoch: 8 [48900/49000 (100%)]\tLoss: 1.572564\n",
      "Train Epoch: 9 [48900/49000 (100%)]\tLoss: 1.554918\n",
      "Train Epoch: 10 [48900/49000 (100%)]\tLoss: 1.551066\n",
      "Train Epoch: 11 [48900/49000 (100%)]\tLoss: 1.534051\n",
      "Train Epoch: 12 [48900/49000 (100%)]\tLoss: 1.584335\n",
      "Train Epoch: 13 [48900/49000 (100%)]\tLoss: 1.561402\n",
      "Train Epoch: 14 [48900/49000 (100%)]\tLoss: 1.569102\n",
      "Train Epoch: 15 [48900/49000 (100%)]\tLoss: 1.576375\n",
      "Train Epoch: 16 [48900/49000 (100%)]\tLoss: 1.535643\n",
      "Train Epoch: 17 [48900/49000 (100%)]\tLoss: 1.523732\n",
      "Train Epoch: 18 [48900/49000 (100%)]\tLoss: 1.556696\n",
      "Train Epoch: 19 [48900/49000 (100%)]\tLoss: 1.531572\n",
      "Train Epoch: 20 [48900/49000 (100%)]\tLoss: 1.545116\n",
      "Train Epoch: 21 [48900/49000 (100%)]\tLoss: 1.582421\n",
      "Train Epoch: 22 [48900/49000 (100%)]\tLoss: 1.574572\n",
      "Train Epoch: 23 [48900/49000 (100%)]\tLoss: 1.542827\n",
      "Train Epoch: 24 [48900/49000 (100%)]\tLoss: 1.518339\n",
      "Train Epoch: 25 [48900/49000 (100%)]\tLoss: 1.515868\n",
      "Train Epoch: 26 [48900/49000 (100%)]\tLoss: 1.561982\n",
      "Train Epoch: 27 [48900/49000 (100%)]\tLoss: 1.605737\n",
      "Train Epoch: 28 [48900/49000 (100%)]\tLoss: 1.524121\n",
      "Train Epoch: 29 [48900/49000 (100%)]\tLoss: 1.547048\n",
      "Train Epoch: 30 [48900/49000 (100%)]\tLoss: 1.519950\n",
      "Train Epoch: 31 [48900/49000 (100%)]\tLoss: 1.541424\n",
      "Train Epoch: 32 [48900/49000 (100%)]\tLoss: 1.527610\n",
      "Train Epoch: 33 [48900/49000 (100%)]\tLoss: 1.558485\n",
      "Train Epoch: 34 [48900/49000 (100%)]\tLoss: 1.513863\n",
      "Train Epoch: 35 [48900/49000 (100%)]\tLoss: 1.530370\n",
      "Train Epoch: 36 [48900/49000 (100%)]\tLoss: 1.566923\n",
      "Train Epoch: 37 [48900/49000 (100%)]\tLoss: 1.551904\n",
      "Train Epoch: 38 [48900/49000 (100%)]\tLoss: 1.554419\n",
      "Train Epoch: 39 [48900/49000 (100%)]\tLoss: 1.540599\n",
      "Train Epoch: 40 [48900/49000 (100%)]\tLoss: 1.543008\n",
      "Train Epoch: 41 [48900/49000 (100%)]\tLoss: 1.515762\n",
      "Train Epoch: 42 [48900/49000 (100%)]\tLoss: 1.538646\n",
      "Train Epoch: 43 [48900/49000 (100%)]\tLoss: 1.530556\n",
      "Train Epoch: 44 [48900/49000 (100%)]\tLoss: 1.558563\n",
      "Train Epoch: 45 [48900/49000 (100%)]\tLoss: 1.514359\n",
      "Train Epoch: 46 [48900/49000 (100%)]\tLoss: 1.551433\n",
      "Train Epoch: 47 [48900/49000 (100%)]\tLoss: 1.528431\n",
      "Train Epoch: 48 [48900/49000 (100%)]\tLoss: 1.547202\n",
      "Train Epoch: 49 [48900/49000 (100%)]\tLoss: 1.573076\n",
      "Train Epoch: 50 [48900/49000 (100%)]\tLoss: 1.555616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hilak\\anaconda3\\envs\\ANN\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 1.5516, Accuracy: 19101/21000 (90.96%)\n",
      "\n",
      "Final test accuracy in torch model:91.0%\n"
     ]
    }
   ],
   "source": [
    "torch_test_acc, _ = test()\n",
    "print(f\"Initial test accuracy in torch model:{torch_test_acc:.1f}%\")\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "  train(epoch)\n",
    "torch_test_acc, torch_test_macro_auc = test()\n",
    "print(f\"Final test accuracy in torch model:{torch_test_acc:.1f}%\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Evaluating the neural networks performance"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "results = [torch_test_macro_auc, one_layer_model_test_macro_auc, two_layers_model_test_macro_auc]\n",
    "models_names = [\"Torch\", \"ANN 1 layer\", \"ANN 2 layers\"]\n",
    "_, ax = plt.subplots()\n",
    "bars = ax.bar(models_names, results)\n",
    "ax.set_ylabel('Macro AUC')\n",
    "ax.set_xlabel('Model')\n",
    "ax.set_ylim(0.975, 1)\n",
    "ax.bar_label(bars, padding=3)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}